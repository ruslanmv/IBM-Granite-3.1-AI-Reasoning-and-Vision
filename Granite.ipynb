{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMHuZiS6G3xHOtqk+Mzv+qL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "583be15bb0524dbb907abf0bfb428184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87df5816043241d880863e9d288778e5",
              "IPY_MODEL_94b92af70c814f11a74d6d835c6f6fb3",
              "IPY_MODEL_092e5cddfc544bfca2d300faac011c1e"
            ],
            "layout": "IPY_MODEL_8a464678fb13478dba89ba6b612dab2c"
          }
        },
        "87df5816043241d880863e9d288778e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c98db7fcfb314323a2774d483c50d007",
            "placeholder": "​",
            "style": "IPY_MODEL_2e720c7bfa8b417084f7dce1a93d6573",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "94b92af70c814f11a74d6d835c6f6fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdfec66f0f5644a7a04bf6ebab5cb7e3",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ab3b62ea8db45b59b194a2c4a3ebcc0",
            "value": 4
          }
        },
        "092e5cddfc544bfca2d300faac011c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7189b6281cf0412b84c2bf83e513f555",
            "placeholder": "​",
            "style": "IPY_MODEL_28f3c6715b2a48d1a04584742d2f0f89",
            "value": " 4/4 [00:10&lt;00:00,  2.33s/it]"
          }
        },
        "8a464678fb13478dba89ba6b612dab2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c98db7fcfb314323a2774d483c50d007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e720c7bfa8b417084f7dce1a93d6573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdfec66f0f5644a7a04bf6ebab5cb7e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ab3b62ea8db45b59b194a2c4a3ebcc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7189b6281cf0412b84c2bf83e513f555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28f3c6715b2a48d1a04584742d2f0f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruslanmv/IBM-Granite-3.1-AI-Reasoning-and-Vision/blob/main/Granite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IBM Granite 3.1 8b Reasoning & Vision Preview\n",
        "code by [ruslamv.com](https://ruslamv.com)"
      ],
      "metadata": {
        "id": "AEkYgXhT1Kzn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMXISSD6NebY",
        "outputId": "3cc7a8db-2743-4d46-b3a1-0c96f425f9bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Granite-Vision-Chatbot repository cloned successfully!\n",
            "mkdir: cannot create directory ‘Granite-Vision-Chatbot’: File exists\n",
            "Moving contents of Granite-Vision-Chatbot to current directory...\n",
            "Contents of Granite-Vision-Chatbot moved successfully!\n",
            "Finished.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Repository URL and name\n",
        "repo_url = \"https://huggingface.co/spaces/ruslanmv/Granite-Vision-Chatbot\"\n",
        "repo_name = \"Granite-Vision-Chatbot\"\n",
        "\n",
        "# Check if the repository directory exists (if so, we'll assume it's already cloned)\n",
        "if not os.path.exists(repo_name):\n",
        "    print(f\"Cloning {repo_name} repository...\")\n",
        "    !git clone {repo_url}\n",
        "    clear_output()\n",
        "    print(f\"{repo_name} repository cloned successfully!\")\n",
        "    !mkdir {repo_name}\n",
        "    # Move contents of the repository to the current directory\n",
        "    print(f\"Moving contents of {repo_name} to current directory...\")\n",
        "    for item in os.listdir(repo_name):\n",
        "        s = os.path.join(repo_name, item)\n",
        "        d = os.path.join(\".\", item)  # Current directory\n",
        "        if os.path.isdir(s):\n",
        "            shutil.move(s, d) # Use move for directories\n",
        "        else:\n",
        "            shutil.move(s, d) # Use move for files\n",
        "    shutil.rmtree(repo_name)  # Remove the now-empty repo directory\n",
        "    print(f\"Contents of {repo_name} moved successfully!\")\n",
        "else:\n",
        "    print(f\"{repo_name} repository already exists. Skipping cloning.\")\n",
        "print(\"Finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def install_requirements(requirements_file=\"requirements.txt\"):\n",
        "    \"\"\"Installs requirements from a given file and clears the output.\"\"\"\n",
        "\n",
        "    if os.path.exists(requirements_file):\n",
        "        print(f\"Installing requirements from {requirements_file}...\")\n",
        "        try:\n",
        "             !pip install -r {requirements_file}\n",
        "             !pip install spaces\n",
        "             clear_output()  # Clear pip install output\n",
        "             print(f\"Requirements from {requirements_file} installed successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error installing requirements: {e}\")\n",
        "    else:\n",
        "        print(f\"Requirements file {requirements_file} not found.\")\n",
        "\n",
        "# 2. Install the requirements\n",
        "\n",
        "install_requirements()  # Installs from requirements.txt in current directory\n",
        "print(\"Finished installing requirements (or skipped if not found).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61jP3xA3OZGg",
        "outputId": "1b6bd7fa-e508-40c0-ba49-c0304b5cce18"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirements file requirements.txt not found.\n",
            "Finished installing requirements (or skipped if not found).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"src\")  # Change to the 'src' directory\n",
        "print(f\"Current directory: {os.getcwd()}\") # Verify the change\n",
        "import gradio as gr\n",
        "import threading\n",
        "import time\n",
        "import subprocess\n",
        "from app import demo"
      ],
      "metadata": {
        "id": "XmOJ5dpjTlJa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.queue().launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "Za0X0PwKbrgV",
        "outputId": "ce6a4eb6-1861-44f8-e7f0-a4b673ca328c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3b3aa15b688bbe9879.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3b3aa15b688bbe9879.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "erbrpJCkx7Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IBM Granite 3.1 8b Reasoning"
      ],
      "metadata": {
        "id": "Q-_1btDt1Gaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# Model and tokenizer\n",
        "model_name = \"ruslanmv/granite-3.1-8b-Reasoning\"  # Or \"ruslanmv/granite-3.1-2b-Reasoning\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Configure 4-bit quantization properly\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,  # Enable 4-bit quantization\n",
        "    bnb_4bit_compute_dtype=torch.float16  # Match dtype to avoid slow inference\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",  # Use GPU if available\n",
        "    torch_dtype=torch.float16,  # Use float16 for faster inference\n",
        "    quantization_config=quantization_config  # Use proper config instead of deprecated argument\n",
        ")\n",
        "\n",
        "# Prepare dataset\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "...\n",
        "</answer>\n",
        "\"\"\"\n",
        "text = tokenizer.apply_chat_template([\n",
        "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "    {\"role\": \"user\", \"content\": \"Calculate pi.\"}  # Example prompt - change this!\n",
        "], tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")  # Move input tensor to GPU\n",
        "\n",
        "# Sampling parameters (Fixed `do_sample` warning)\n",
        "generation_config = GenerationConfig(\n",
        "    do_sample=True,  # Ensure sample-based settings are applied\n",
        "    temperature=0.8,  # Active only when `do_sample=True`\n",
        "    top_p=0.95,  # Active only when `do_sample=True`\n",
        "    max_new_tokens=1024,  # Control response length\n",
        ")\n",
        "\n",
        "# Inference\n",
        "with torch.inference_mode():  # Use inference mode for faster generation\n",
        "    outputs = model.generate(**inputs, generation_config=generation_config)\n",
        "\n",
        "output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Find the start of the actual response\n",
        "start_index = output.find(\"assistant\")\n",
        "if start_index != -1:\n",
        "    # Remove the initial part including \"assistant\"\n",
        "    output = output[start_index + len(\"assistant\"):].strip()\n",
        "\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197,
          "referenced_widgets": [
            "583be15bb0524dbb907abf0bfb428184",
            "87df5816043241d880863e9d288778e5",
            "94b92af70c814f11a74d6d835c6f6fb3",
            "092e5cddfc544bfca2d300faac011c1e",
            "8a464678fb13478dba89ba6b612dab2c",
            "c98db7fcfb314323a2774d483c50d007",
            "2e720c7bfa8b417084f7dce1a93d6573",
            "fdfec66f0f5644a7a04bf6ebab5cb7e3",
            "3ab3b62ea8db45b59b194a2c4a3ebcc0",
            "7189b6281cf0412b84c2bf83e513f555",
            "28f3c6715b2a48d1a04584742d2f0f89"
          ]
        },
        "id": "gd5g_N1lxjNO",
        "outputId": "45c7fa79-3a4b-4a46-8d6a-0cd28b31eac8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "583be15bb0524dbb907abf0bfb428184"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<reasoning>\n",
            "Pi (π) is an irrational number, which means it cannot be precisely calculated to a finite number of decimal places. However, it can be approximated using various mathematical formulas. One common method to approximate pi is using the Leibniz formula for π: π = 4 * (1 - 1/3 + 1/5 - 1/7 + 1/9 -...). This formula converges very slowly, so it requires many terms to get an accurate approximation.\n",
            "</reasoning>\n",
            "\n",
            "<answer>\n",
            "The value of pi using the Leibniz formula with the first five terms is approximately 3.439692653589793.\n",
            "</answer>\n"
          ]
        }
      ]
    }
  ]
}